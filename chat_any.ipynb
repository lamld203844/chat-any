{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamld203844/chat-any/blob/main/chat_any.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45zCoVjWP49j"
      },
      "source": [
        "# System flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pwtnTyNdWMV"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q langchain-community\n",
        "!pip install -q llama-index\n",
        "\n",
        "!pip install -q llama-index-embeddings-langchain\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "!pip install -q llama-index-llms-gemini\n",
        "!pip install -q google-generativeai\n",
        "!pip install -q llama-index-readers-web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDFzArGBiYOW"
      },
      "source": [
        "## Load file\n",
        "- load website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjKWlYSriaFk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------------------------------\n",
        "# Load data from a website via Llamaindex Loader\n",
        "#\n",
        "# -------------------------------------------\n",
        "\n",
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from IPython.display import Markdown, display\n",
        "import os\n",
        "\n",
        "url = 'https://cinnamon.is/en/company/'\n",
        "loader = SimpleWebPageReader(html_to_text=True)\n",
        "docs = loader.load_data([url])\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xikTNUriVNRX"
      },
      "source": [
        "## Chunking and creating embeddings model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Caching embedding models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HF_HOME\"] = \"/teamspace/studios/this_studio/weights\"\n",
        "os.environ[\"TORCH_HOME\"] = \"/teamspace/studios/this_studio/weights\"\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-small-en')\n",
        "model = AutoModel.from_pretrained('BAAI/bge-small-en')\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Load embeddings model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX1aUNUfNxjY",
        "outputId": "67a647a1-8d34-45d2-eb01-d17aa2cff410"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --------------------------------------------\n",
        "# Chunking and create embeddings\n",
        "# Automatic via llama index VectorStoreIndex\n",
        "# --------------------------------------------\n",
        "from torch import cuda \n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "def load_embedding_model(\n",
        "    model_name: str = \"BAAI/bge-small-en\",\n",
        "    device: str = \"cuda\" if cuda.is_available() else \"cpu\"\n",
        ") -> HuggingFaceBgeEmbeddings:\n",
        "    model_kwargs = {\"device\": device}\n",
        "    encode_kwargs = {\n",
        "        \"normalize_embeddings\": True\n",
        "    }  # set True to compute cosine similarity\n",
        "    embedding_model = HuggingFaceBgeEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs,\n",
        "    )\n",
        "    return embedding_model\n",
        "\n",
        "# setting up the embedding model\n",
        "lc_embedding_model = load_embedding_model()\n",
        "embed_model = LangchainEmbedding(lc_embedding_model)\n",
        "\n",
        "### Sanity check embedding model\n",
        "embedding = lc_embedding_model.embed_query('Hello, world')\n",
        "embedding = embedding[:10]\n",
        "print(f'Embedding: {embedding}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "460ec774bda54dd29da57bf313c877e8",
            "4124c7030d9448f6a2f0f312c717d92a",
            "af925b0ca8e84713aa94532af835b69e",
            "641ec30a759f4ccfa6f6834d129b6c4e",
            "80b9c3f5a0134c37b15664cf93d603a3",
            "6b1d02d0b25b4818ba1c7e0860533c86",
            "4cecaec3b11c4915a5a0ca8a0092e1e0",
            "9244cbd583c049c8a1ccad35fe31186d",
            "9467733a47a947bfbff60575465e3706",
            "416aa61e14014266aef39637e8182c78",
            "14f2fc9deb5f412a88fa7694bace7752",
            "9252b45e0ffd472a9df77218e2a3b00b",
            "db5960481a92496a9f384ea565815965",
            "27f17b36e8704cd0b9c6a3965c93af14",
            "07999175b7db48d6a9a5ae59b651428b",
            "afdd8058a1134c0eba7dd218a60ac623",
            "4d9e20e7c0d94fc4aafc7c385dcedf85",
            "7978afa8c91b462d913329881e35a2a7",
            "15d0e6881e8a4134b61ddcfdb3cdd545",
            "1dedae21d4fc4be19c461dc4ffad53b2",
            "9ac65e4a4b3348dcbef179ad494f4927",
            "a39a3b3f845b4267982f56e6b8e87298"
          ]
        },
        "id": "RaVCrosIdy_H",
        "outputId": "8b3fa0a1-0d13-415d-a3d4-031deb26d028"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "# ====== Create vector store and upload data ======\n",
        "Settings.embed_model = lc_embedding_model\n",
        "index = VectorStoreIndex.from_documents(docs, show_progress=True)\n",
        "# TODO try async index creation for faster emebdding generation & persist it to memory!\n",
        "# index = VectorStoreIndex(docs, use_async=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP1yyMtZVWKx"
      },
      "source": [
        "## Load llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jbbfYZZNVZeF",
        "outputId": "9b80823e-8070-46ed-8dd1-79c96de1af82"
      },
      "outputs": [],
      "source": [
        "# setting up the llm\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "google_api = os.environ['GOOGLE_API_KEY']\n",
        "llm = Gemini(model_name=\"models/gemini-pro\", api_key=google_api)\n",
        "\n",
        "# Sanity check llm\n",
        "resp = llm.complete(\"Hello, world\")\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9WsHNoveIlP"
      },
      "source": [
        "## Prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6I02L3QeKer"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ====== Setup a query engine ======\n",
        "Settings.llm = llm\n",
        "query_engine = index.as_query_engine(similarity_top_k=4)\n",
        "\n",
        "# ---------------------------------------\n",
        "# Customise prompt template + augmenting\n",
        "# ---------------------------------------\n",
        "\n",
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "qa_prompt_tmpl_str = (\n",
        "  \"You are a formal, friendly and supportive assistant for question answering from given website (Answer questions in complete sentences).\\n\"\n",
        "  \"Answer the question using the following information delimited by triple brackque.:\\n\\n\"\n",
        "  \"```\\n{context_str}\\n```\"\n",
        "  \"Question: {query_str}\\n\"\n",
        "  \"\\nYou can format ouput in a aesthetic way. Remember: Don't say based on information provided or something like that\"\n",
        "  \"\\nIn case you don't know the answer or any exception occur, say 'I don't know!'\"\n",
        ")\n",
        "\n",
        "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
        "\n",
        "query_engine.update_prompts(\n",
        "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "MpgJ3bmieM2G",
        "outputId": "bc2fd6c3-31b1-43c9-cb95-16e51b49e3a2"
      },
      "outputs": [],
      "source": [
        "# ---------- Chatting -----------\n",
        "from IPython.display import Markdown, display\n",
        "response = query_engine.query('What is this website about?')\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVEqUqJcKPdH"
      },
      "source": [
        "# Wrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HF_HOME\"] = \"/teamspace/studios/this_studio/weights\"\n",
        "os.environ[\"TORCH_HOME\"] = \"/teamspace/studios/this_studio/weights\"\n",
        "\n",
        "import gc\n",
        "import re # website url validation\n",
        "import uuid # unique id for each session\n",
        "import nest_asyncio # allows nested access to the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from torch import cuda\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv() # Load Gemini API\n",
        "\n",
        "\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import PromptTemplate\n",
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "from llama_index.llms.gemini import Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup embedding model\n",
        "\n",
        "def load_embedding_model(\n",
        "    model_name: str = \"BAAI/bge-small-en\",\n",
        "    device: str = \"cuda\" if cuda.is_available() else \"cpu\"\n",
        ") -> HuggingFaceBgeEmbeddings:\n",
        "    model_kwargs = {\"device\": device}\n",
        "    encode_kwargs = {\n",
        "        \"normalize_embeddings\": True\n",
        "    }  # set True to compute cosine similarity\n",
        "    embedding_model = HuggingFaceBgeEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs,\n",
        "    )\n",
        "    return embedding_model\n",
        "\n",
        "# setting up the embedding model\n",
        "lc_embedding_model = load_embedding_model()\n",
        "embed_model = LangchainEmbedding(lc_embedding_model)\n",
        "\n",
        "# setup llm\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "google_api = os.environ['GOOGLE_API_KEY']\n",
        "llm = Gemini(model_name=\"models/gemini-pro\", api_key=google_api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re \n",
        "\n",
        "def validate_website_url(url):\n",
        "\n",
        "    url_pattern = re.compile(\n",
        "        r'http[s]?://'  # http:// or https://\n",
        "        r'(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|'  # domain...\n",
        "        r'(?:%[0-9a-fA-F][0-9a-fA-F]))+'  # ...or percent-encoded characters\n",
        "        r'(?:\\:[0-9]{1,5})?'  # optional port number\n",
        "        r'(?:/[a-zA-Z0-9$-_@.&+!*\\\\(\\\\),=%]*)*'  # path\n",
        "        r'(?:\\?[a-zA-Z0-9$-_@.&+!*\\\\(\\\\),=%]*)?'  # query string\n",
        "        r'(?:#[a-zA-Z0-9$-_@.&+!*\\\\(\\\\),=%]*)?'  # fragment\n",
        "    )\n",
        "    return bool(url_pattern.match(url))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_query_engine(website_url):\n",
        "    if validate_website_url(website_url):\n",
        "        try:\n",
        "            # -------------------------------------------\n",
        "            # Load data from a website via Llamaindex Loader\n",
        "            # -------------------------------------------\n",
        "            loader = SimpleWebPageReader()\n",
        "            docs = loader.load_data([website_url])\n",
        "\n",
        "            # ---- Create vector store and upload data ---\n",
        "            # Chunking and create embeddings\n",
        "            # Automatic via llama index VectorStoreIndex\n",
        "            # --------------------------------------------\n",
        "            Settings.embed_model = embed_model\n",
        "            index = VectorStoreIndex.from_documents(docs, show_progress=True)\n",
        "\n",
        "            # ====== Setup a query engine ======\n",
        "            Settings.llm = llm\n",
        "            query_engine = index.as_query_engine(similarity_top_k=4)\n",
        "\n",
        "            # ====== Customise prompt template ======\n",
        "            qa_prompt_tmpl_str = (\n",
        "                \"You are a formal, friendly and supportive assistant for question answering from given website (Answer questions in complete sentences).\\n\"\n",
        "                \"Answer the question using the following information delimited by triple brackque.:\\n\\n\"\n",
        "                \"```\\n{context_str}\\n```\"\n",
        "                \"Question: {query_str}\\n\"\n",
        "                \"\\nYou can format ouput in a aesthetic way. Remember: Don't say based on information provided or something like that\"\n",
        "                \"\\nIn case you don't know the answer or any exception occur, say 'I don't know!'\"\n",
        "            )\n",
        "            qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
        "\n",
        "            query_engine.update_prompts(\n",
        "                {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
        "            )\n",
        "            # ======= Complete setting up !!!! ========\n",
        "            if docs:\n",
        "                print(\"Data loaded successfully!!\")\n",
        "                print(\"Ready to chat!!\")\n",
        "            else:\n",
        "                print(\"No data found, check if the repository is not empty!\")\n",
        "            \n",
        "            return query_engine\n",
        "        except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "    else:\n",
        "        print('Invalid github repo, try again!')\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = 'https://cinnamon.is/en/company/'\n",
        "query_engine = setup_query_engine(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNutYfasKgcp"
      },
      "outputs": [],
      "source": [
        "# ---------- Chatting -----------\n",
        "from IPython.display import Markdown, display\n",
        "response = query_engine.query('role of Dr. Hajime Hotta in company')\n",
        "display(Markdown(str(response)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtP64HZYOXyG"
      },
      "source": [
        "# GUI with Streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwm1IsD3zMkY",
        "outputId": "701fc7bf-f545-45b5-ca70-179a5e70b29b"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q langchain-community\n",
        "!pip install -q llama-index\n",
        "\n",
        "!pip install -q llama-index-embeddings-langchain\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "!pip install -q llama-index-llms-gemini\n",
        "!pip install -q google-generativeai\n",
        "!pip install -q llama-index-readers-web\n",
        "\n",
        "!pip install -q streamlit\n",
        "!npm install -q localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTJRvp0KOeUU",
        "outputId": "2da9102d-d901-42d4-e59c-c83f8535617e"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"HF_HOME\"] = \"/teamspace/studios/this_studio/weights\"\n",
        "os.environ[\"TORCH_HOME\"] = \"/teamspace/studios/this_studio/weights\"\n",
        "\n",
        "import gc\n",
        "import re # website url validation\n",
        "import uuid # unique id for each session\n",
        "import nest_asyncio # allows nested access to the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import streamlit as st\n",
        "from torch import cuda\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv() # Load Gemini API\n",
        "\n",
        "\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import PromptTemplate\n",
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "\n",
        "# ---------- Init + Helper function ----------------\n",
        "\n",
        "# os.environ['HF_HOME'] = '\\lit-chat_with_code_RAG\\weights' # for run embedding model locally\n",
        "\n",
        "# setting up the embedding model\n",
        "def load_embedding_model(\n",
        "    model_name: str = \"BAAI/bge-small-en\",\n",
        "    device: str = \"cuda\" if cuda.is_available() else \"cpu\"\n",
        ") -> HuggingFaceBgeEmbeddings:\n",
        "    model_kwargs = {\"device\": device}\n",
        "    encode_kwargs = {\n",
        "        \"normalize_embeddings\": True\n",
        "    }  # set True to compute cosine similarity\n",
        "    embedding_model = HuggingFaceBgeEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs,\n",
        "    )\n",
        "    return embedding_model\n",
        "\n",
        "lc_embedding_model = load_embedding_model()\n",
        "embed_model = LangchainEmbedding(lc_embedding_model)\n",
        "\n",
        "# setting up session\n",
        "if \"id\" not in st.session_state:\n",
        "    st.session_state.id = uuid.uuid4()\n",
        "    st.session_state.file_cache = {}\n",
        "\n",
        "session_id = st.session_state.id\n",
        "client = None\n",
        "\n",
        "# setting up the llm\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "llm = Gemini(model_name=\"models/gemini-pro\", api_key=os.environ['GOOGLE_API_KEY'])\n",
        "\n",
        "# helper func\n",
        "def reset_chat():\n",
        "    st.session_state.messages = []\n",
        "    st.session_state.context = None\n",
        "    gc.collect() # free up memory\n",
        "\n",
        "def validate_website_url(url):\n",
        "\n",
        "    url_pattern = re.compile(\n",
        "        r'http[s]?://'  # http:// or https://\n",
        "        r'(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|'  # domain...\n",
        "        r'(?:%[0-9a-fA-F][0-9a-fA-F]))+'  # ...or percent-encoded characters\n",
        "        r'(?:\\:[0-9]{1,5})?'  # optional port number\n",
        "        r'(?:/[a-zA-Z0-9$-_@.&+!*\\\\(\\\\),=%]*)*'  # path\n",
        "        r'(?:\\?[a-zA-Z0-9$-_@.&+!*\\\\(\\\\),=%]*)?'  # query string\n",
        "        r'(?:#[a-zA-Z0-9$-_@.&+!*\\\\(\\\\),=%]*)?'  # fragment\n",
        "    )\n",
        "    return bool(url_pattern.match(url))\n",
        "\n",
        "# ---------- End helper function ----------------\n",
        "\n",
        "with st.sidebar:\n",
        "    # Input for URL\n",
        "    website_url = st.text_input(\"URL\")\n",
        "\n",
        "    # Button to load and process url\n",
        "    load_button = st.button(\"Load\")\n",
        "\n",
        "    message_container = st.empty()  # Placeholder for dynamic messages\n",
        "\n",
        "    if load_button and website_url:\n",
        "        if validate_website_url(website_url):\n",
        "            with st.spinner(f\"Loading website...\"):\n",
        "                try:\n",
        "                    # -------------------------------------------\n",
        "                    # Load data from a website via Llamaindex Loader\n",
        "                    # -------------------------------------------\n",
        "                    loader = SimpleWebPageReader()\n",
        "                    docs = loader.load_data([website_url])\n",
        "\n",
        "                    # ---- Create vector store and upload data ---\n",
        "                    # Chunking and create embeddings\n",
        "                    # Automatic via llama index VectorStoreIndex\n",
        "                    # --------------------------------------------\n",
        "                    Settings.embed_model = embed_model\n",
        "                    index = VectorStoreIndex.from_documents(docs)\n",
        "\n",
        "                    # ====== Setup a query engine ======\n",
        "                    Settings.llm = llm\n",
        "                    query_engine = index.as_query_engine(similarity_top_k=4) # TODO\n",
        "                    # query_engine = index.as_query_engine(streaming=True, similarity_top_k=4) # TODO\n",
        "\n",
        "                    # ====== Customise prompt template ======\n",
        "                    qa_prompt_tmpl_str = (\n",
        "                        \"You are a formal, friendly and supportive assistant (Answer questions in complete sentences).\\n\"\n",
        "                        \"Answer the question using the following information delimited by triple brackque, in case you don't know the answer say 'I don't know!':\\n\\n\"\n",
        "                        \"```\\n{context_str}\\n```\"\n",
        "                        \"Query: {query_str}\\n\"\n",
        "                        \"\\nYou can format output as you want but try to give the answer which c above.\"\n",
        "                        \"\\nDon't say based on information provided or something like that\"\n",
        "                    )\n",
        "                    qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
        "\n",
        "                    query_engine.update_prompts(\n",
        "                        {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
        "                    )\n",
        "                    # ======= Complete setting up !!!! ========\n",
        "                    if docs:\n",
        "                        message_container.success(\"Data loaded successfully!!\")\n",
        "                    else:\n",
        "                        message_container.write(\n",
        "                            \"No data found, check if the repository is not empty!\"\n",
        "                        )\n",
        "                    st.session_state.query_engine = query_engine\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"An error occurred: {e}\")\n",
        "                    st.stop()\n",
        "\n",
        "                st.success(\"Ready to Chat!\")\n",
        "        else:\n",
        "            st.error('Invalid url')\n",
        "            st.stop()\n",
        "\n",
        "col1, col2 = st.columns([6, 1])\n",
        "\n",
        "with col1:\n",
        "    st.header(f\"Chat with any website\")\n",
        "\n",
        "with col2:\n",
        "    st.button(\"Clear ↺\", on_click=reset_chat)\n",
        "\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    reset_chat()\n",
        "\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "\n",
        "# Accept user input\n",
        "if prompt := st.chat_input(\"What's up?\"):\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    # Display user message in chat message container\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    # Display assistant response in chat message container\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        message_placeholder = st.empty()\n",
        "\n",
        "        query_engine = st.session_state.query_engine\n",
        "        full_response = query_engine.query(prompt)\n",
        "        # # TODO: Simulate stream of response with milliseconds delay\n",
        "        # full_response = \"\"\n",
        "        # streaming_response = query_engine.query(prompt)\n",
        "\n",
        "        # for chunk in streaming_response.response_gen:\n",
        "        #     full_response += chunk\n",
        "        #     message_placeholder.markdown(full_response + \"▌\")\n",
        "\n",
        "        message_placeholder.markdown(full_response)\n",
        "\n",
        "    # Add assistant response to chat history\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSpquYwROi7V",
        "outputId": "460146c4-a5bb-44cc-be64-ad120a56ea2d"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPgmSct5zjas8twgX477qSo",
      "collapsed_sections": [
        "CVEqUqJcKPdH"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07999175b7db48d6a9a5ae59b651428b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac65e4a4b3348dcbef179ad494f4927",
            "placeholder": "​",
            "style": "IPY_MODEL_a39a3b3f845b4267982f56e6b8e87298",
            "value": " 2/2 [00:00&lt;00:00,  6.07it/s]"
          }
        },
        "14f2fc9deb5f412a88fa7694bace7752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15d0e6881e8a4134b61ddcfdb3cdd545": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dedae21d4fc4be19c461dc4ffad53b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27f17b36e8704cd0b9c6a3965c93af14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15d0e6881e8a4134b61ddcfdb3cdd545",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dedae21d4fc4be19c461dc4ffad53b2",
            "value": 2
          }
        },
        "4124c7030d9448f6a2f0f312c717d92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1d02d0b25b4818ba1c7e0860533c86",
            "placeholder": "​",
            "style": "IPY_MODEL_4cecaec3b11c4915a5a0ca8a0092e1e0",
            "value": "Parsing nodes: 100%"
          }
        },
        "416aa61e14014266aef39637e8182c78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460ec774bda54dd29da57bf313c877e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4124c7030d9448f6a2f0f312c717d92a",
              "IPY_MODEL_af925b0ca8e84713aa94532af835b69e",
              "IPY_MODEL_641ec30a759f4ccfa6f6834d129b6c4e"
            ],
            "layout": "IPY_MODEL_80b9c3f5a0134c37b15664cf93d603a3"
          }
        },
        "4cecaec3b11c4915a5a0ca8a0092e1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d9e20e7c0d94fc4aafc7c385dcedf85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641ec30a759f4ccfa6f6834d129b6c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_416aa61e14014266aef39637e8182c78",
            "placeholder": "​",
            "style": "IPY_MODEL_14f2fc9deb5f412a88fa7694bace7752",
            "value": " 1/1 [00:00&lt;00:00, 14.49it/s]"
          }
        },
        "6b1d02d0b25b4818ba1c7e0860533c86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7978afa8c91b462d913329881e35a2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80b9c3f5a0134c37b15664cf93d603a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9244cbd583c049c8a1ccad35fe31186d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9252b45e0ffd472a9df77218e2a3b00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db5960481a92496a9f384ea565815965",
              "IPY_MODEL_27f17b36e8704cd0b9c6a3965c93af14",
              "IPY_MODEL_07999175b7db48d6a9a5ae59b651428b"
            ],
            "layout": "IPY_MODEL_afdd8058a1134c0eba7dd218a60ac623"
          }
        },
        "9467733a47a947bfbff60575465e3706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ac65e4a4b3348dcbef179ad494f4927": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39a3b3f845b4267982f56e6b8e87298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af925b0ca8e84713aa94532af835b69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9244cbd583c049c8a1ccad35fe31186d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9467733a47a947bfbff60575465e3706",
            "value": 1
          }
        },
        "afdd8058a1134c0eba7dd218a60ac623": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5960481a92496a9f384ea565815965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d9e20e7c0d94fc4aafc7c385dcedf85",
            "placeholder": "​",
            "style": "IPY_MODEL_7978afa8c91b462d913329881e35a2a7",
            "value": "Generating embeddings: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
